{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:42:58.117395Z",
     "iopub.status.busy": "2024-11-24T16:42:58.117052Z",
     "iopub.status.idle": "2024-11-24T16:42:58.122023Z",
     "shell.execute_reply": "2024-11-24T16:42:58.121137Z",
     "shell.execute_reply.started": "2024-11-24T16:42:58.117366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install nibabel monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is done by Manpurwar Ganesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:42:58.126876Z",
     "iopub.status.busy": "2024-11-24T16:42:58.126633Z",
     "iopub.status.idle": "2024-11-24T16:43:01.232256Z",
     "shell.execute_reply": "2024-11-24T16:43:01.231566Z",
     "shell.execute_reply.started": "2024-11-24T16:42:58.126852Z"
    },
    "id": "zIv6nJg-7b0m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the PatchPartition module\n",
    "\n",
    "class PatchPartition(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=4, out_channels=48, patch_size=2):\n",
    "\n",
    "        super(PatchPartition, self).__init__()\n",
    "\n",
    "        self.patch_partition = nn.Conv3d(\n",
    "\n",
    "            in_channels=in_channels,\n",
    "\n",
    "            out_channels=out_channels,\n",
    "\n",
    "            kernel_size=patch_size,\n",
    "\n",
    "            stride=patch_size,\n",
    "\n",
    "            padding=0\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Input shape: (B, H, W, D, C)\n",
    "\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # Convert to (B, C, H, W, D)\n",
    "\n",
    "        x = self.patch_partition(x)   # Output shape: (B, 48, H/2, W/2, D/2)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 4, 1)  # Convert to (B, H/2, W/2, D/2, 48)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Define the WindowMultiHeadSelfAttention module\n",
    "\n",
    "class WindowMultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, window_size, mlp_dim):\n",
    "\n",
    "        super(WindowMultiHeadSelfAttention, self).__init__()\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(mlp_dim, dim)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.window_size = window_size\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, H, W, D, C = x.shape\n",
    "\n",
    "        x_norm = self.norm1(x)\n",
    "\n",
    "\n",
    "\n",
    "        x_windowed = x_norm.view(B, H // self.window_size[0], self.window_size[0],\n",
    "\n",
    "                                 W // self.window_size[1], self.window_size[1],\n",
    "\n",
    "                                 D // self.window_size[2], self.window_size[2], C)\n",
    "\n",
    "        x_windowed = x_windowed.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
    "\n",
    "        x_windowed = x_windowed.view(-1, self.window_size[0] * self.window_size[1] * self.window_size[2], C)\n",
    "\n",
    "\n",
    "\n",
    "        attn_output, _ = self.attention(x_windowed, x_windowed, x_windowed)\n",
    "\n",
    "        attn_output = attn_output.view(B, H // self.window_size[0], W // self.window_size[1],\n",
    "\n",
    "                                       D // self.window_size[2], self.window_size[0],\n",
    "\n",
    "                                       self.window_size[1], self.window_size[2], C)\n",
    "\n",
    "        attn_output = attn_output.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous()\n",
    "\n",
    "        attn_output = attn_output.view(B, H, W, D, C)\n",
    "\n",
    "\n",
    "\n",
    "        w_msa_output = x + attn_output\n",
    "\n",
    "        x_linear = self.linear(w_msa_output)\n",
    "\n",
    "        x_linear_norm = self.norm2(x_linear)\n",
    "\n",
    "        mlp_output = self.mlp(x_linear_norm)\n",
    "\n",
    "\n",
    "\n",
    "        output = w_msa_output + mlp_output\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Define the ShiftedWindowMultiHeadSelfAttention module\n",
    "\n",
    "class ShiftedWindowMultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, window_size, shift_size, mlp_dim):\n",
    "\n",
    "        super(ShiftedWindowMultiHeadSelfAttention, self).__init__()\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(mlp_dim, dim)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.shift_size = shift_size\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, H, W, D, C = x.shape\n",
    "\n",
    "        shifted_x = torch.roll(x, shifts=(-self.shift_size[0], -self.shift_size[1], -self.shift_size[2]), dims=(1, 2, 3))\n",
    "\n",
    "        x_norm = self.norm1(shifted_x)\n",
    "\n",
    "\n",
    "\n",
    "        x_windowed = x_norm.view(B, H // self.window_size[0], self.window_size[0],\n",
    "\n",
    "                                 W // self.window_size[1], self.window_size[1],\n",
    "\n",
    "                                 D // self.window_size[2], self.window_size[2], C)\n",
    "\n",
    "        x_windowed = x_windowed.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
    "\n",
    "        x_windowed = x_windowed.view(-1, self.window_size[0] * self.window_size[1] * self.window_size[2], C)\n",
    "\n",
    "\n",
    "\n",
    "        attn_output, _ = self.attention(x_windowed, x_windowed, x_windowed)\n",
    "\n",
    "        attn_output = attn_output.view(B, H // self.window_size[0], W // self.window_size[1],\n",
    "\n",
    "                                       D // self.window_size[2], self.window_size[0],\n",
    "\n",
    "                                       self.window_size[1], self.window_size[2], C)\n",
    "\n",
    "        attn_output = attn_output.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous()\n",
    "\n",
    "        attn_output = attn_output.view(B, H, W, D, C)\n",
    "\n",
    "\n",
    "\n",
    "        unshifted_attn_output = torch.roll(attn_output, shifts=(self.shift_size[0], self.shift_size[1], self.shift_size[2]), dims=(1, 2, 3))\n",
    "\n",
    "        sw_msa_output = x + unshifted_attn_output\n",
    "\n",
    "        x_linear = self.linear(sw_msa_output)\n",
    "\n",
    "        x_linear_norm = self.norm2(x_linear)\n",
    "\n",
    "        mlp_output = self.mlp(x_linear_norm)\n",
    "\n",
    "\n",
    "\n",
    "        output = sw_msa_output + mlp_output\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Define the PatchMerging module\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "\n",
    "        super(PatchMerging, self).__init__()\n",
    "\n",
    "        self.reduction = nn.Linear(8 * dim, 2 * dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, H, W, D, C = x.shape\n",
    "\n",
    "        x = x.view(B, H // 2, 2, W // 2, 2, D // 2, 2, C)\n",
    "\n",
    "        x = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
    "\n",
    "        x = x.view(B, H // 2, W // 2, D // 2, 8 * C)\n",
    "\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        return x  # Shape: (B, H/2, W/2, D/2, 2*C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:01.234248Z",
     "iopub.status.busy": "2024-11-24T16:43:01.233810Z",
     "iopub.status.idle": "2024-11-24T16:43:01.239839Z",
     "shell.execute_reply": "2024-11-24T16:43:01.238852Z",
     "shell.execute_reply.started": "2024-11-24T16:43:01.234215Z"
    },
    "id": "Jron8sSi7iWJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SwinPipeline(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, window_size, shift_size, mlp_dim):\n",
    "\n",
    "        super(SwinPipeline, self).__init__()\n",
    "\n",
    "        self.attention_module1 = WindowMultiHeadSelfAttention(dim=dim, num_heads=num_heads, window_size=window_size, mlp_dim=mlp_dim)\n",
    "\n",
    "        self.attention_module2 = ShiftedWindowMultiHeadSelfAttention(dim=dim, num_heads=num_heads, window_size=window_size, shift_size=shift_size, mlp_dim=mlp_dim)\n",
    "\n",
    "        self.patch_merging = PatchMerging(dim=dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.attention_module1(x)\n",
    "\n",
    "        x = self.attention_module2(x)\n",
    "\n",
    "        x = self.patch_merging(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:01.241383Z",
     "iopub.status.busy": "2024-11-24T16:43:01.241040Z",
     "iopub.status.idle": "2024-11-24T16:43:01.390281Z",
     "shell.execute_reply": "2024-11-24T16:43:01.389205Z",
     "shell.execute_reply.started": "2024-11-24T16:43:01.241346Z"
    },
    "id": "7IjTNd-luNQw",
    "outputId": "b547805f-2d1c-409d-8fae-ad68a8d48267",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 32, 32, 32, 48])\n"
     ]
    }
   ],
   "source": [
    "B, H, W, D = 2, 64, 64, 64  # Example batch size and dimensions\n",
    "\n",
    "input_tensor = torch.randn(B, H, W, D, 4)  # Input tensor with shape (B, H, W, D, 4)\n",
    "\n",
    "patch_partition = PatchPartition(out_channels=48)\n",
    "\n",
    "patch_output = patch_partition(input_tensor)\n",
    "\n",
    "print(\"Output shape:\", patch_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:01.391644Z",
     "iopub.status.busy": "2024-11-24T16:43:01.391342Z",
     "iopub.status.idle": "2024-11-24T16:43:05.267338Z",
     "shell.execute_reply": "2024-11-24T16:43:05.266368Z",
     "shell.execute_reply.started": "2024-11-24T16:43:01.391614Z"
    },
    "id": "eVZQzZbjvvNv",
    "outputId": "c67bf1b1-06bb-40fd-f26d-15165ebabeac",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of stage 1: torch.Size([2, 16, 16, 16, 96])\n",
      "Output shape of stage 2: torch.Size([2, 8, 8, 8, 192])\n",
      "Output shape of stage 3: torch.Size([2, 4, 4, 4, 384])\n",
      "Output shape of stage 4: torch.Size([2, 2, 2, 2, 768])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = patch_output\n",
    "\n",
    "\n",
    "\n",
    "pipeline = SwinPipeline(dim=48, num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2), mlp_dim=96)\n",
    "\n",
    "stage_1_output = pipeline(input_tensor)\n",
    "\n",
    "print(\"Output shape of stage 1:\", stage_1_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "# patch_out=dim=mlp_dim//2\n",
    "\n",
    "input_tensor = stage_1_output\n",
    "\n",
    "\n",
    "\n",
    "pipeline = SwinPipeline(dim=96, num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2), mlp_dim=192)\n",
    "\n",
    "stage_2_output = pipeline(input_tensor)\n",
    "\n",
    "print(\"Output shape of stage 2:\", stage_2_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = stage_2_output\n",
    "\n",
    "\n",
    "\n",
    "pipeline = SwinPipeline(dim=192, num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2), mlp_dim=384)\n",
    "\n",
    "stage_3_output = pipeline(input_tensor)\n",
    "\n",
    "print(\"Output shape of stage 3:\", stage_3_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = stage_3_output\n",
    "\n",
    "\n",
    "\n",
    "pipeline = SwinPipeline(dim=384, num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2), mlp_dim=768)\n",
    "\n",
    "stage_4_output = pipeline(input_tensor)\n",
    "\n",
    "print(\"Output shape of stage 4:\", stage_4_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.270565Z",
     "iopub.status.busy": "2024-11-24T16:43:05.270192Z",
     "iopub.status.idle": "2024-11-24T16:43:05.277452Z",
     "shell.execute_reply": "2024-11-24T16:43:05.276600Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.270535Z"
    },
    "id": "1Wel93VPUIN3",
    "outputId": "059fea2a-82e6-4d5d-8eb3-a4d0aea0bf44",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 48, 32, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_output = patch_output.permute(0,4,1,2,3)\n",
    "\n",
    "patch_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.279057Z",
     "iopub.status.busy": "2024-11-24T16:43:05.278588Z",
     "iopub.status.idle": "2024-11-24T16:43:05.290255Z",
     "shell.execute_reply": "2024-11-24T16:43:05.289401Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.279013Z"
    },
    "id": "Rksr2idaxKmc",
    "outputId": "62dfd43a-8521-4741-e5b5-4dfbdd60268e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "stage_4_output = stage_4_output.permute(0,4,1,2,3)\n",
    "\n",
    "print(stage_4_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXymC4YCwdvW"
   },
   "source": [
    "## stage 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is written by Sai Aditya Kudipudi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.291922Z",
     "iopub.status.busy": "2024-11-24T16:43:05.291637Z",
     "iopub.status.idle": "2024-11-24T16:43:05.750798Z",
     "shell.execute_reply": "2024-11-24T16:43:05.749667Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.291872Z"
    },
    "id": "NRxxM9YtTKoq",
    "outputId": "ee4d0484-c753-4832-c4f2-2c9e5b8986cd",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([2, 384, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, bottleneck_channels):\n",
    "\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, bottleneck_channels, kernel_size=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(bottleneck_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(bottleneck_channels, bottleneck_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm3d(bottleneck_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(bottleneck_channels, in_channels, kernel_size=1)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm3d(in_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet3DBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "\n",
    "        super(ResNet3DBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        # Reduce the number of channels from in_channels to mid_channels\n",
    "\n",
    "        self.channel_reduction = nn.Conv3d(in_channels, mid_channels, kernel_size=1)\n",
    "\n",
    "        # Use a 3D transpose convolution to upscale the spatial dimensions\n",
    "\n",
    "        self.upsample = nn.ConvTranspose3d(mid_channels, mid_channels, kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.channel_reduction(x)  # Reduce channels\n",
    "\n",
    "        x = self.upsample(x)  # Upsample spatial dimensions\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class FinalPipeline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=768, bottleneck_channels=384):\n",
    "\n",
    "        super(FinalPipeline, self).__init__()\n",
    "\n",
    "        self.bottleneck_block = BottleneckBlock(in_channels=in_channels, bottleneck_channels=bottleneck_channels)\n",
    "\n",
    "        self.resnet_block = ResNet3DBlock(channels=in_channels)\n",
    "\n",
    "        self.feature_extractor = FeatureExtractor(in_channels=in_channels, mid_channels=bottleneck_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply bottleneck block\n",
    "\n",
    "        x = self.bottleneck_block(x)\n",
    "\n",
    "        # print(\"After BottleneckBlock:\", x.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply ResNet block\n",
    "\n",
    "        x = self.resnet_block(x)\n",
    "\n",
    "        # print(\"After ResNet3DBlock:\", x.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply feature extractor for channel reduction and upsampling\n",
    "\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # print(\"After FeatureExtractor:\", x.shape)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "H, W, D = 2, 2, 2  # Example input spatial dimensions for stage 4 output\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "\n",
    "# Create an example input tensor with shape (batch_size, 768, H, W, D)\n",
    "\n",
    "stage_4_output = torch.randn(batch_size, 768, H, W, D)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate and apply the pipeline\n",
    "\n",
    "pipeline = FinalPipeline(in_channels=768, bottleneck_channels=384)\n",
    "\n",
    "skip_connection_4 = pipeline(stage_4_output)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Final output shape:\", skip_connection_4.shape)  # Expected: (batch_size, 384, H * 2, W * 2, D * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ-0b0H4yDNu"
   },
   "source": [
    "## Stage skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.752295Z",
     "iopub.status.busy": "2024-11-24T16:43:05.751969Z",
     "iopub.status.idle": "2024-11-24T16:43:05.758021Z",
     "shell.execute_reply": "2024-11-24T16:43:05.757185Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.752268Z"
    },
    "id": "uXzvu9bBycj0",
    "outputId": "1c15dab8-27db-4e1e-9caf-aaea90e0063d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384, 4, 4, 4])\n",
      "torch.Size([2, 192, 8, 8, 8])\n",
      "torch.Size([2, 96, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "stage_3_output = stage_3_output.permute(0,4,1,2,3)\n",
    "\n",
    "print(stage_3_output.shape)\n",
    "\n",
    "stage_2_output = stage_2_output.permute(0,4,1,2,3)\n",
    "\n",
    "print(stage_2_output.shape)\n",
    "\n",
    "stage_1_output = stage_1_output.permute(0,4,1,2,3)\n",
    "\n",
    "print(stage_1_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.759575Z",
     "iopub.status.busy": "2024-11-24T16:43:05.759312Z",
     "iopub.status.idle": "2024-11-24T16:43:05.767586Z",
     "shell.execute_reply": "2024-11-24T16:43:05.766666Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.759551Z"
    },
    "id": "ef30o8NARmzd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HiddenFeature_1(nn.Module):#used at end of stage 1 for converstion\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(HiddenFeature_1, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Upsample to double the spatial dimensions (H/2, W/2, D/2) -> (H, W, D)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolution to reduce channels from 4*C to C\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "        # ReLU activation\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Upsample the spatial dimensions\n",
    "\n",
    "        x = self.upsample(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply the convolution to reduce channels from 4*C to C\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply activation function\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.769383Z",
     "iopub.status.busy": "2024-11-24T16:43:05.768646Z",
     "iopub.status.idle": "2024-11-24T16:43:05.779910Z",
     "shell.execute_reply": "2024-11-24T16:43:05.778961Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.769337Z"
    },
    "id": "qGd_xjO8FIR2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNet3DBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "\n",
    "        super(ResNet3DBlock, self).__init__()\n",
    "\n",
    "        # First 3D convolutional layer with batch normalization and ReLU\n",
    "\n",
    "        self.conv1 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "\n",
    "        # Second 3D convolutional layer with batch normalization\n",
    "\n",
    "        self.conv2 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x  # Save the input for the skip connection\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "\n",
    "\n",
    "\n",
    "        # Add the identity (skip connection)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        out = F.relu(out)  # Final ReLU activation\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.781336Z",
     "iopub.status.busy": "2024-11-24T16:43:05.781053Z",
     "iopub.status.idle": "2024-11-24T16:43:05.790861Z",
     "shell.execute_reply": "2024-11-24T16:43:05.790073Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.781307Z"
    },
    "id": "4_5bEAiDxsFd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class HiddenFeature(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "\n",
    "        super(HiddenFeature, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # A 3D convolution that preserves the input dimensions and channels\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "        # ReLU activation\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply the convolution\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply the activation function\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.792287Z",
     "iopub.status.busy": "2024-11-24T16:43:05.792007Z",
     "iopub.status.idle": "2024-11-24T16:43:05.804794Z",
     "shell.execute_reply": "2024-11-24T16:43:05.804016Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.792258Z"
    },
    "id": "W1G37YKnFIR3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HiddenLayer_1(nn.Module):#\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(HiddenLayer_1, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Upsample to double the spatial dimensions (H/2, W/2, D/2) -> (H, W, D)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolution to reduce channels from 2*C to C\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "        # ReLU activation\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Upsample the spatial dimensions\n",
    "\n",
    "        x = self.upsample(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply the convolution to reduce channels from 2*C to C\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply activation function\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.806089Z",
     "iopub.status.busy": "2024-11-24T16:43:05.805806Z",
     "iopub.status.idle": "2024-11-24T16:43:05.815624Z",
     "shell.execute_reply": "2024-11-24T16:43:05.814765Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.806060Z"
    },
    "id": "QRLkOhxbGL3E",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(HiddenLayer, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # Upsample spatial dimensions from (H/2, W/2, D/2) to (H, W, D)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "\n",
    "\n",
    "\n",
    "        # 3D convolution to reduce channels from 2*C to C\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "        # ReLU activation\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Upsample spatial dimensions\n",
    "\n",
    "        x = self.upsample(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Reduce channels from 2*C to C\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply ReLU activation\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:05.819667Z",
     "iopub.status.busy": "2024-11-24T16:43:05.819110Z",
     "iopub.status.idle": "2024-11-24T16:43:06.102102Z",
     "shell.execute_reply": "2024-11-24T16:43:06.101262Z",
     "shell.execute_reply.started": "2024-11-24T16:43:05.819632Z"
    },
    "id": "QNwrnAOFOBw2",
    "outputId": "680182df-9224-4dfe-a61c-0921b8b29700",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a class that combines the operations in the example usage\n",
    "\n",
    "class ModelPipeline(nn.Module):#used at stage 1,2,3\n",
    "\n",
    "    def __init__(self, C):\n",
    "\n",
    "        super(ModelPipeline, self).__init__()\n",
    "\n",
    "        self.resnet_1 = ResNet3DBlock(channels=C)\n",
    "\n",
    "        self.hidden_1 = HiddenFeature(channels=C)\n",
    "\n",
    "        self.resnet_block_after_concat = ResNet3DBlock(channels=2 * C)\n",
    "\n",
    "        self.hidden_feature_1 = HiddenFeature_1(in_channels=2 * C, out_channels=C // 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        hidden_1_output = self.hidden_1(x1)\n",
    "\n",
    "        # print(\"Hidden feature output shape:\", hidden_1_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "        resnet_1_output = self.resnet_1(hidden_1_output)\n",
    "\n",
    "        # print(\"ResNet block 1 output shape:\", resnet_1_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "        concatenated_output = torch.cat((resnet_1_output, x2), dim=1)\n",
    "\n",
    "        # print(\"Concatenated output shape:\", concatenated_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "        resnet_2_output = self.resnet_block_after_concat(concatenated_output)\n",
    "\n",
    "        # print(\"ResNet block after concatenation output shape:\", resnet_2_output.shape)\n",
    "\n",
    "\n",
    "\n",
    "        output_tensor = self.hidden_feature_1(resnet_2_output)\n",
    "\n",
    "        # print(\"Final output tensor shape:\", output_tensor.shape)\n",
    "\n",
    "\n",
    "\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "H, W, D, C = 16, 16, 16, 96\n",
    "\n",
    "x1 = torch.randn(1, C, H, W, D)\n",
    "\n",
    "x2 = torch.randn(1, C, H, W, D)\n",
    "\n",
    "\n",
    "\n",
    "model = ModelPipeline(C=C)\n",
    "\n",
    "output = model(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:06.103703Z",
     "iopub.status.busy": "2024-11-24T16:43:06.103310Z",
     "iopub.status.idle": "2024-11-24T16:43:07.041437Z",
     "shell.execute_reply": "2024-11-24T16:43:07.040557Z",
     "shell.execute_reply.started": "2024-11-24T16:43:06.103665Z"
    },
    "id": "8OWPqYixJJVv",
    "outputId": "df18e334-0b88-4a4a-8ea6-54d090aa48fa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 48, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class ModelPipeline_1(nn.Module):#used at stage 0\n",
    "\n",
    "    def __init__(self, C):\n",
    "\n",
    "        super(ModelPipeline_1, self).__init__()\n",
    "\n",
    "        self.resnet_1 = ResNet3DBlock(channels=C)\n",
    "\n",
    "        self.hidden_1 = HiddenFeature(channels=C)\n",
    "\n",
    "        self.resnet_block_after_concat = ResNet3DBlock(channels=2 * C)\n",
    "\n",
    "        self.hidden_layer_final = HiddenLayer(in_channels=2 * C, out_channels=C)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "\n",
    "\n",
    "        hidden_1_output = self.hidden_1(x1)\n",
    "\n",
    "        # Pass x1 through the first ResNet block\n",
    "\n",
    "        resnet_1_output = self.resnet_1(hidden_1_output)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate the output of ResNet block with x2 along the channel dimension\n",
    "\n",
    "        concatenated_output = torch.cat((hidden_1_output, x2), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Pass the concatenated output through another ResNet block\n",
    "\n",
    "        resnet_2_output = self.resnet_block_after_concat(concatenated_output)\n",
    "\n",
    "\n",
    "\n",
    "        # Pass the output through the final HiddenLayer block to reduce channels\n",
    "\n",
    "        final_output = self.hidden_layer_final(resnet_2_output)\n",
    "\n",
    "\n",
    "\n",
    "        return final_output\n",
    "\n",
    "\n",
    "\n",
    "H, W, D, C = 32, 32, 32, 48\n",
    "\n",
    "x1 = torch.randn(1, C, H, W, D)\n",
    "\n",
    "x2 = torch.randn(1, C, H, W, D)\n",
    "\n",
    "\n",
    "\n",
    "model = ModelPipeline_1(C=C)\n",
    "\n",
    "\n",
    "\n",
    "output_tensor = model(x1, x2)\n",
    "\n",
    "\n",
    "\n",
    "# Print output shape\n",
    "\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:07.043028Z",
     "iopub.status.busy": "2024-11-24T16:43:07.042405Z",
     "iopub.status.idle": "2024-11-24T16:43:07.649783Z",
     "shell.execute_reply": "2024-11-24T16:43:07.648801Z",
     "shell.execute_reply.started": "2024-11-24T16:43:07.042989Z"
    },
    "id": "5Psa3Vld6vVE",
    "outputId": "77498521-24a7-4f43-8821-06c0b127de86",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([2, 192, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = stage_3_output\n",
    "\n",
    "skip_tensor = skip_connection_4\n",
    "\n",
    "C = 384\n",
    "\n",
    "# Create pipeline instance and forward pass\n",
    "\n",
    "pipeline = ModelPipeline(C=C)\n",
    "\n",
    "skip_connection_3 = pipeline(input_tensor, skip_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# Print final output shape\n",
    "\n",
    "print(\"Final output shape:\", skip_connection_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:07.651407Z",
     "iopub.status.busy": "2024-11-24T16:43:07.651048Z",
     "iopub.status.idle": "2024-11-24T16:43:07.948317Z",
     "shell.execute_reply": "2024-11-24T16:43:07.947373Z",
     "shell.execute_reply.started": "2024-11-24T16:43:07.651376Z"
    },
    "id": "_pdMPx0Xzu6Y",
    "outputId": "08ae52ac-351c-4517-b065-7782f6bc6ff3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([2, 96, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = stage_2_output\n",
    "\n",
    "skip_tensor = skip_connection_3\n",
    "\n",
    "C = 192\n",
    "\n",
    "# Create pipeline instance and forward pass\n",
    "\n",
    "pipeline = ModelPipeline(C=C)\n",
    "\n",
    "skip_connection_2 = pipeline(input_tensor, skip_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# Print final output shape\n",
    "\n",
    "print(\"Final output shape:\", skip_connection_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:07.949705Z",
     "iopub.status.busy": "2024-11-24T16:43:07.949417Z",
     "iopub.status.idle": "2024-11-24T16:43:08.422192Z",
     "shell.execute_reply": "2024-11-24T16:43:08.421164Z",
     "shell.execute_reply.started": "2024-11-24T16:43:07.949679Z"
    },
    "id": "Bjuj8lkn5usZ",
    "outputId": "2563581b-7bcb-464c-f788-b1eef23f6449",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape: torch.Size([2, 48, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = stage_1_output\n",
    "\n",
    "skip_tensor = skip_connection_2\n",
    "\n",
    "C = 96\n",
    "\n",
    "# Create pipeline instance and forward pass\n",
    "\n",
    "pipeline = ModelPipeline(C=C)\n",
    "\n",
    "skip_connection_1 = pipeline(input_tensor, skip_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# Print final output shape\n",
    "\n",
    "print(\"Final output shape:\", skip_connection_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:08.423639Z",
     "iopub.status.busy": "2024-11-24T16:43:08.423350Z",
     "iopub.status.idle": "2024-11-24T16:43:10.015640Z",
     "shell.execute_reply": "2024-11-24T16:43:10.014597Z",
     "shell.execute_reply.started": "2024-11-24T16:43:08.423612Z"
    },
    "id": "pVm0edh8K80w",
    "outputId": "3ad6d075-98c7-44ec-d43d-7dbf16ea6a4d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 48, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "H, W, D, C = 32, 32, 32, 48\n",
    "\n",
    "input_tensor = patch_output\n",
    "\n",
    "skip_tensor = skip_connection_1\n",
    "\n",
    "\n",
    "\n",
    "pipeline_0 = ModelPipeline_1(C=C)\n",
    "\n",
    "\n",
    "\n",
    "skip_connection_0 = pipeline_0(input_tensor, skip_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# Print output shape\n",
    "\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Stage  pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:10.017087Z",
     "iopub.status.busy": "2024-11-24T16:43:10.016699Z",
     "iopub.status.idle": "2024-11-24T16:43:11.558166Z",
     "shell.execute_reply": "2024-11-24T16:43:11.557231Z",
     "shell.execute_reply.started": "2024-11-24T16:43:10.017058Z"
    },
    "id": "euYtO8Z4LRmK",
    "outputId": "db4da3e0-75c8-40a3-cb62-85fb460850db",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 48, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class FeaturePipeline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=4, mid_channels=48, out_channels=48):\n",
    "\n",
    "        super(FeaturePipeline, self).__init__()\n",
    "\n",
    "        # Define the first 1x1 convolution to increase channels from in_channels to mid_channels\n",
    "\n",
    "        self.conv1x1_increase = nn.Conv3d(in_channels=in_channels, out_channels=mid_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Define a simple ResNet block with mid_channels as input/output\n",
    "\n",
    "        self.resnet_block = ResNet3DBlock(channels=mid_channels)\n",
    "\n",
    "\n",
    "\n",
    "        # Define the second 1x1 convolution to reduce channels from 2 * mid_channels to out_channels\n",
    "\n",
    "        self.conv1x1_reduce = nn.Conv3d(in_channels=2 * mid_channels, out_channels=out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor, skip_tensor):\n",
    "\n",
    "        # Apply the first 1x1 convolution\n",
    "\n",
    "        x = self.conv1x1_increase(input_tensor)\n",
    "\n",
    "        # Apply the ResNet block\n",
    "\n",
    "        x = self.resnet_block(x)\n",
    "\n",
    "        # Concatenate with the skip tensor along the channel dimension\n",
    "\n",
    "        x = torch.cat((x, skip_tensor), dim=1)\n",
    "\n",
    "        # Apply the second 1x1 convolution\n",
    "\n",
    "        x = self.conv1x1_reduce(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "H, W, D, C = 64, 64, 64, 48\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "pipeline = FeaturePipeline(in_channels=4, mid_channels=48, out_channels=48)\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = torch.randn(batch_size, 4, H, W, D)\n",
    "\n",
    "skip_tensor = skip_connection_0\n",
    "\n",
    "\n",
    "\n",
    "output_tensor = pipeline(input_tensor, skip_tensor)\n",
    "\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:11.559663Z",
     "iopub.status.busy": "2024-11-24T16:43:11.559332Z",
     "iopub.status.idle": "2024-11-24T16:43:11.568320Z",
     "shell.execute_reply": "2024-11-24T16:43:11.567406Z",
     "shell.execute_reply.started": "2024-11-24T16:43:11.559635Z"
    },
    "id": "hC4Kq4EQr70X",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HeadBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=48, out_channels=3):\n",
    "\n",
    "        super(HeadBlock, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # First 3D convolution to refine the features\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        # Second 3D convolution layer (optional for further refinement)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 48, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        # Final 1x1x1 convolution to reduce to the desired output channels (3)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(48, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Optionally, Softmax or Sigmoid can be applied on the output, depending on the task\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)  # For multi-class segmentation\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Pass through the first conv layer and ReLU activation\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.relu1(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Pass through the second conv layer and ReLU activation\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.relu2(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Final 1x1x1 conv to project features to the desired output channels\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply Softmax activation (for multi-class segmentation)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin- UNETR Final Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:11.569732Z",
     "iopub.status.busy": "2024-11-24T16:43:11.569475Z",
     "iopub.status.idle": "2024-11-24T16:43:11.583696Z",
     "shell.execute_reply": "2024-11-24T16:43:11.582944Z",
     "shell.execute_reply.started": "2024-11-24T16:43:11.569708Z"
    },
    "id": "fq1jIIh3RY6U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SwinUnetr(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "\n",
    "      super(SwinUnetr, self).__init__()\n",
    "\n",
    "      self.patch_partition = PatchPartition(out_channels = 48)\n",
    "\n",
    "\n",
    "\n",
    "      # Define a simple ResNet block with mid_channels as input/output\n",
    "\n",
    "      self.swin_stage_1= SwinPipeline(dim=48,num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2),mlp_dim=96)\n",
    "\n",
    "      self.swin_stage_2= SwinPipeline(dim=96,num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2),mlp_dim=192)\n",
    "\n",
    "      self.swin_stage_3= SwinPipeline(dim=192,num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2),mlp_dim=384)\n",
    "\n",
    "      self.swin_stage_4= SwinPipeline(dim=384,num_heads=4, window_size=(4, 4, 4), shift_size=(2, 2, 2),mlp_dim=768)\n",
    "\n",
    "\n",
    "\n",
    "      self.final_pipeline = FinalPipeline(in_channels=768, bottleneck_channels=384)\n",
    "\n",
    "      self.intermediate_pipeline_3 = ModelPipeline(C=384)\n",
    "\n",
    "      self.intermediate_pipeline_2 = ModelPipeline(C=192)\n",
    "\n",
    "      self.intermediate_pipeline_1 = ModelPipeline(C=96)\n",
    "\n",
    "\n",
    "\n",
    "      self.start_pipeline = ModelPipeline_1(C=48)\n",
    "\n",
    "\n",
    "\n",
    "      self.feature_pipeline = FeaturePipeline(in_channels=4,mid_channels=48,out_channels=48)\n",
    "\n",
    "      self.head_block = HeadBlock(in_channels=48, out_channels=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      B,H,W,D,C=input_tensor.shape\n",
    "\n",
    "      patch_output = self.patch_partition(input_tensor)\n",
    "\n",
    "\n",
    "\n",
    "      stage_1_output = self.swin_stage_1(patch_output)\n",
    "\n",
    "      stage_2_output = self.swin_stage_2(stage_1_output)\n",
    "\n",
    "      stage_3_output = self.swin_stage_3(stage_2_output)\n",
    "\n",
    "      stage_4_output = self.swin_stage_4(stage_3_output)\n",
    "\n",
    "\n",
    "\n",
    "      stage_4_output = stage_4_output.permute(0,4,1,2,3)\n",
    "\n",
    "      stage_3_output = stage_3_output.permute(0,4,1,2,3)\n",
    "\n",
    "      stage_2_output = stage_2_output.permute(0,4,1,2,3)\n",
    "\n",
    "      stage_1_output = stage_1_output.permute(0,4,1,2,3)\n",
    "\n",
    "      patch_output = patch_output.permute(0,4,1,2,3)\n",
    "\n",
    "\n",
    "\n",
    "      skip_connection_4 = self.final_pipeline(stage_4_output)\n",
    "\n",
    "      skip_connection_3 = self.intermediate_pipeline_3(stage_3_output,skip_connection_4)\n",
    "\n",
    "      skip_connection_2 = self.intermediate_pipeline_2(stage_2_output,skip_connection_3)\n",
    "\n",
    "      skip_connection_1 = self.intermediate_pipeline_1(stage_1_output,skip_connection_2)\n",
    "\n",
    "      skip_connection_0 = self.start_pipeline(patch_output,skip_connection_1)\n",
    "\n",
    "      input_tensor = input_tensor.permute(0,4,1,2,3)\n",
    "\n",
    "\n",
    "\n",
    "      feature_output = self.feature_pipeline(input_tensor,skip_connection_0)\n",
    "\n",
    "      segmentation_output = self.head_block(feature_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      return segmentation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:11.585053Z",
     "iopub.status.busy": "2024-11-24T16:43:11.584764Z",
     "iopub.status.idle": "2024-11-24T16:43:19.952391Z",
     "shell.execute_reply": "2024-11-24T16:43:19.951321Z",
     "shell.execute_reply.started": "2024-11-24T16:43:11.585028Z"
    },
    "id": "mUOV8OhbkaE1",
    "outputId": "ad20ef3e-e8e3-4871-925c-4944ebf0e7d3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "swin_unetr = SwinUnetr()\n",
    "\n",
    "input_tensor = torch.randn(2,64,64,64,4)\n",
    "\n",
    "output_tensor = swin_unetr(input_tensor)\n",
    "\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is from data reduction file by Kushwanth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:19.953753Z",
     "iopub.status.busy": "2024-11-24T16:43:19.953466Z",
     "iopub.status.idle": "2024-11-24T16:43:21.464012Z",
     "shell.execute_reply": "2024-11-24T16:43:21.463206Z",
     "shell.execute_reply.started": "2024-11-24T16:43:19.953723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BRATS2021Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "\n",
    "            root_dir (string): Directory with all patient folders containing .nii files.\n",
    "\n",
    "            transform (callable, optional): Optional transform to apply on a sample.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.patients = sorted(os.listdir(root_dir))  # List of patient folders\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.patients)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        patient_dir = os.path.join(self.root_dir, self.patients[idx])\n",
    "\n",
    "\n",
    "\n",
    "        # Define the modality filenames\n",
    "\n",
    "        flair_path = os.path.join(patient_dir, f\"{self.patients[idx]}_flair.nii\")\n",
    "\n",
    "        t1_path = os.path.join(patient_dir, f\"{self.patients[idx]}_t1.nii\")\n",
    "\n",
    "        t1ce_path = os.path.join(patient_dir, f\"{self.patients[idx]}_t1ce.nii\")\n",
    "\n",
    "        t2_path = os.path.join(patient_dir, f\"{self.patients[idx]}_t2.nii\")\n",
    "\n",
    "        seg_path = os.path.join(patient_dir, f\"{self.patients[idx]}_seg.nii\")\n",
    "\n",
    "\n",
    "\n",
    "        # Load modalities using nibabel\n",
    "\n",
    "        flair = nib.load(flair_path).get_fdata(dtype=np.float32)\n",
    "\n",
    "        t1 = nib.load(t1_path).get_fdata(dtype=np.float32)\n",
    "\n",
    "        t1ce = nib.load(t1ce_path).get_fdata(dtype=np.float32)\n",
    "\n",
    "        t2 = nib.load(t2_path).get_fdata(dtype=np.float32)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Stack modalities into a single tensor (e.g., shape: [4, H, W, D])\n",
    "\n",
    "        modalities = torch.tensor(np.stack([flair, t1, t1ce, t2], axis=0))\n",
    "\n",
    "\n",
    "\n",
    "        # Load segmentation\n",
    "\n",
    "        seg = nib.load(seg_path).get_fdata(dtype=np.float32)\n",
    "\n",
    "        segmentation = torch.tensor(seg, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "        # Apply transformations if any\n",
    "\n",
    "        if self.transform:\n",
    "\n",
    "            modalities = self.transform(modalities)\n",
    "\n",
    "            segmentation = self.transform(segmentation)\n",
    "\n",
    "        modalities = modalities.squeeze(dim=1)\n",
    "\n",
    "        segmentation = segmentation.squeeze(dim=0)\n",
    "\n",
    "        modalities = modalities.permute(1, 2, 3, 0)\n",
    "\n",
    "        segmentation[segmentation == 4] = 2\n",
    "\n",
    "\n",
    "\n",
    "        return modalities, segmentation\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5, 0.5])  # Normalize modalities\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.465398Z",
     "iopub.status.busy": "2024-11-24T16:43:21.465019Z",
     "iopub.status.idle": "2024-11-24T16:43:21.577860Z",
     "shell.execute_reply": "2024-11-24T16:43:21.577113Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.465372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"D:/swin-dataset/Processed_BraTS2021/train\" \n",
    "\n",
    "train_dataset = BRATS2021Dataset(root_dir=train_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "test_dir = \"D:/swin-dataset/Processed_BraTS2021/test\"   \n",
    "\n",
    "test_dataset = BRATS2021Dataset(root_dir=test_dir)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "validation_dir = \"D:swin-dataset/Processed_BraTS2021/val\"     \n",
    "validation_dataset = BRATS2021Dataset(root_dir=validation_dir)\n",
    "\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.579190Z",
     "iopub.status.busy": "2024-11-24T16:43:21.578914Z",
     "iopub.status.idle": "2024-11-24T16:43:21.776657Z",
     "shell.execute_reply": "2024-11-24T16:43:21.775750Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.579164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_img = next(iter(validation_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.778052Z",
     "iopub.status.busy": "2024-11-24T16:43:21.777691Z",
     "iopub.status.idle": "2024-11-24T16:43:21.783885Z",
     "shell.execute_reply": "2024-11-24T16:43:21.782942Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.778025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.785333Z",
     "iopub.status.busy": "2024-11-24T16:43:21.785040Z",
     "iopub.status.idle": "2024-11-24T16:43:21.795129Z",
     "shell.execute_reply": "2024-11-24T16:43:21.794173Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.785289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 64, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.796594Z",
     "iopub.status.busy": "2024-11-24T16:43:21.796274Z",
     "iopub.status.idle": "2024-11-24T16:43:21.821832Z",
     "shell.execute_reply": "2024-11-24T16:43:21.820867Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.796563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(train_img[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is done by Aditya Kudupudi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:43:21.823845Z",
     "iopub.status.busy": "2024-11-24T16:43:21.823001Z",
     "iopub.status.idle": "2024-11-24T16:43:21.832090Z",
     "shell.execute_reply": "2024-11-24T16:43:21.831236Z",
     "shell.execute_reply.started": "2024-11-24T16:43:21.823808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, smooth=1e-6):\n",
    "\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "        self.smooth = smooth\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Computes the Dice Loss for multi-class segmentation.\n",
    "\n",
    "        \n",
    "\n",
    "        Args:\n",
    "\n",
    "            preds (torch.Tensor): Predicted tensor of shape (B, C, H, W, D) with raw logits.\n",
    "\n",
    "            targets (torch.Tensor): Ground truth tensor of shape (B, H, W, D) with class indices.\n",
    "\n",
    "        \n",
    "\n",
    "        Returns:\n",
    "\n",
    "            torch.Tensor: The Dice Loss.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Apply softmax to get class probabilities\n",
    "\n",
    "        preds = F.softmax(preds, dim=1)  # Softmax along the channel axis\n",
    "\n",
    "        \n",
    "\n",
    "        # Get the number of classes from predictions\n",
    "\n",
    "        num_classes = preds.shape[1]\n",
    "\n",
    "        \n",
    "\n",
    "        # Convert targets to one-hot encoding of shape (B, C, H, W, D)\n",
    "\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=num_classes)  # Shape: (B, H, W, D, C)\n",
    "\n",
    "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()  # Shape: (B, C, H, W, D)\n",
    "\n",
    "        \n",
    "\n",
    "        # Compute Dice Loss per class\n",
    "\n",
    "        dice_loss = 0\n",
    "\n",
    "        for c in range(num_classes):\n",
    "\n",
    "            pred_flat = preds[:, c].contiguous().view(-1)\n",
    "\n",
    "            target_flat = targets_one_hot[:, c].contiguous().view(-1)\n",
    "\n",
    "            intersection = (pred_flat * target_flat).sum()\n",
    "\n",
    "            dice_score = (2. * intersection ) / (pred_flat.sum() + target_flat.sum() + self.smooth)\n",
    "\n",
    "            dice_loss += 1 - dice_score\n",
    "\n",
    "\n",
    "\n",
    "        # Average Dice Loss across all classes\n",
    "\n",
    "        return dice_loss / num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define checkpoint directory\n",
    "\n",
    "# checkpoint_dir = 'D:\\checkpoints'\n",
    "\n",
    "# os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:54:07.021070Z",
     "iopub.status.busy": "2024-11-24T16:54:07.020315Z",
     "iopub.status.idle": "2024-11-24T16:54:07.028071Z",
     "shell.execute_reply": "2024-11-24T16:54:07.027241Z",
     "shell.execute_reply.started": "2024-11-24T16:54:07.021036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Finds the checkpoint file with the highest epoch number in the given directory.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        checkpoint_dir (str): Path to the directory containing checkpoint files.\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        str: Path to the checkpoint file with the highest epoch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Regex to capture epoch numbers in filenames\n",
    "\n",
    "    epoch_pattern = re.compile(r\"model_epoch_(\\d+)\\.pth\")\n",
    "\n",
    "    \n",
    "\n",
    "    latest_epoch = -1\n",
    "\n",
    "    latest_checkpoint = None\n",
    "\n",
    "    \n",
    "\n",
    "    # Iterate over files in the directory\n",
    "\n",
    "    for file_name in os.listdir(checkpoint_dir):\n",
    "\n",
    "        match = epoch_pattern.search(file_name)\n",
    "\n",
    "        if match:\n",
    "\n",
    "            epoch = int(match.group(1))\n",
    "\n",
    "            if epoch > latest_epoch:\n",
    "\n",
    "                latest_epoch = epoch\n",
    "\n",
    "                latest_checkpoint = os.path.join(checkpoint_dir, file_name)\n",
    "\n",
    "    \n",
    "\n",
    "    if latest_checkpoint is None:\n",
    "\n",
    "        raise FileNotFoundError(f\"No checkpoint files found in {checkpoint_dir}.\")\n",
    "\n",
    "    \n",
    "\n",
    "    return latest_checkpoint, latest_epoch\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device='cuda'):\n",
    "\n",
    "    # Load the checkpoint\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    \n",
    "\n",
    "    # Restore model state\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    \n",
    "\n",
    "    # Restore optimizer state\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    \n",
    "\n",
    "    # Restore the starting epoch\n",
    "\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Checkpoint loaded. Resuming training from epoch {start_epoch}.\")\n",
    "\n",
    "    return start_epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:54:10.367129Z",
     "iopub.status.busy": "2024-11-24T16:54:10.366406Z",
     "iopub.status.idle": "2024-11-24T16:54:10.426268Z",
     "shell.execute_reply": "2024-11-24T16:54:10.425415Z",
     "shell.execute_reply.started": "2024-11-24T16:54:10.367094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "CUDA available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU detected'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T16:54:58.492188Z",
     "iopub.status.busy": "2024-11-24T16:54:58.491464Z",
     "iopub.status.idle": "2024-11-24T16:54:59.610646Z",
     "shell.execute_reply": "2024-11-24T16:54:59.609962Z",
     "shell.execute_reply.started": "2024-11-24T16:54:58.492155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store losses, learning rates, and epochs\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "learning_rates = []\n",
    "\n",
    "epochs = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the device - use GPU if available, otherwise fall back to CPU\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model and send it to the device\n",
    "\n",
    "model = SwinUnetr().to(device)\n",
    "\n",
    "dice_loss_fn = DiceLoss()\n",
    "\n",
    "# Optimizer setup with initial learning rate 1e-2\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs=10, device='cuda', resume_from_checkpoint=None):\n",
    "    start_epoch = 0\n",
    "\n",
    "    if resume_from_checkpoint:\n",
    "        start_epoch = load_checkpoint(model, optimizer, resume_from_checkpoint, device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Define the ReduceLROnPlateau scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_lr = optimizer.param_groups[0]['lr']  # Get the initial learning rate for this epoch\n",
    "        epochs.append(epoch + 1)  # Store the epoch number\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} (Learning Rate: {epoch_lr})\")\n",
    "\n",
    "        # Loop over the batches in the train loader\n",
    "        with tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\") as t:\n",
    "            for batch_idx, (data, target) in enumerate(t):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                optimizer.zero_grad()  # Clear the gradients\n",
    "\n",
    "                # Forward pass through the model\n",
    "                output = model(data)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = dice_loss_fn(output, target)\n",
    "\n",
    "                # Backward pass to compute gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Optimize the parameters (Adam optimizer)\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track the loss and learning rate\n",
    "                epoch_loss += loss.item()\n",
    "                train_losses.append(loss.item())\n",
    "                learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "                # Update tqdm with loss info\n",
    "                t.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Print average epoch loss\n",
    "        print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "        # Optionally: Evaluate the model on the validation set\n",
    "        val_loss = validate(model, val_loader, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Step the scheduler with the validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Save checkpoint every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss / len(train_loader),\n",
    "                'val_loss': val_loss\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Validation loop\n",
    "def validate(model, val_loader, device='cuda'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    val_loss = 0.0\n",
    "    print(\"\\nValidating...\")\n",
    "    with tqdm(val_loader, desc=\"Validation\") as t:\n",
    "        with torch.no_grad():  # No gradients during evaluation\n",
    "            for data, target in t:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = dice_loss_fn(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Update tqdm with loss info\n",
    "                t.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Print the validation loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return avg_val_loss  # Return the validation loss for the scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T16:59:22.119375Z",
     "iopub.status.idle": "2024-11-24T16:59:22.119858Z",
     "shell.execute_reply": "2024-11-24T16:59:22.119647Z",
     "shell.execute_reply.started": "2024-11-24T16:59:22.119623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Directory containing checkpoints\n",
    "\n",
    "checkpoint_dir = \"path to dir\"\n",
    "\n",
    "\n",
    "\n",
    "# Find the latest checkpoint\n",
    "\n",
    "# latest_checkpoint, latest_epoch = find_latest_checkpoint(\"/kaggle/working\")\n",
    "\n",
    "\n",
    "\n",
    "# Resume training\n",
    "\n",
    "# print(f\"Resuming training from checkpoint: {latest_checkpoint} (epoch {latest_epoch})\")\n",
    "\n",
    "# start_epoch = load_checkpoint(model, optimizer, latest_checkpoint, device=device)\n",
    "\n",
    "\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, num_epochs=70,  resume_from_checkpoint=None,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validate(model,test_dataloader,device,dice_loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting the losses and learning rates after training\n",
    "def plot_metrics():\n",
    "\n",
    "    # Plot training loss\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(train_losses, label='Training Loss', color='b')\n",
    "\n",
    "    plt.title('Training Loss')\n",
    "\n",
    "    plt.xlabel('Batch')\n",
    "\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    # Plot validation loss\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(val_losses, label='Validation Loss', color='r')\n",
    "\n",
    "    plt.title('Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_metrics()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6143482,
     "sourceId": 9983425,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6146921,
     "sourceId": 9988289,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6156278,
     "sourceId": 10001577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

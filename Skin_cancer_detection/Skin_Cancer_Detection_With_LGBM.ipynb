{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMes2XHhZEywZETn0CdH5ki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh1729m/Machine-Learning-Works/blob/main/Skin_Cancer_Detection_With_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQS1l34OKKbR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
        "\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
        "\n",
        "import lightgbm as lgb\n",
        "df_train = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\n",
        "df_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\n",
        "\n",
        "# Handle duplicate positive samples\n",
        "positive_samples = df_train[df_train['target'] == 1]\n",
        "positive_samples_duplicated = pd.concat([positive_samples] * 100, ignore_index=True)\n",
        "\n",
        "df_train = pd.concat([df_train, positive_samples_duplicated], ignore_index=True)\n",
        "\n",
        "def feature_engineering(df):\n",
        "    # New features to try...\n",
        "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
        "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
        "    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
        "    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
        "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
        "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
        "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
        "    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2)\n",
        "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
        "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
        "    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
        "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
        "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
        "\n",
        "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
        "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
        "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
        "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
        "    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
        "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
        "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
        "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
        "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
        "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
        "    df[\"3d_lesion_orientation\"] = np.arctan2(df_train[\"tbp_lv_y\"], df_train[\"tbp_lv_x\"])\n",
        "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
        "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
        "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
        "\n",
        "    new_num_cols = [\n",
        "        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n",
        "        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n",
        "        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\",\n",
        "        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"color_consistency\",\n",
        "\n",
        "        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\",\n",
        "        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n",
        "        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n",
        "        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n",
        "        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n",
        "    ]\n",
        "    new_cat_cols = [\"combined_anatomical_site\"]\n",
        "    return df, new_num_cols, new_cat_cols\n",
        "\n",
        "df_train, new_num_cols, new_cat_cols = feature_engineering(df_train.copy())\n",
        "df_test, _, _ = feature_engineering(df_test.copy())\n",
        "\n",
        "num_cols = [\n",
        "    'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext',\n",
        "    'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L',\n",
        "    'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean',\n",
        "    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
        "    'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
        "    'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
        "    'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
        "    'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
        "    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
        "] + new_num_cols\n",
        "# anatom_site_general\n",
        "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
        "train_cols = new_num_cols + cat_cols\n",
        "\n",
        "category_encoder = OrdinalEncoder(\n",
        "    categories='auto',\n",
        "    dtype=int,\n",
        "    handle_unknown='use_encoded_value',\n",
        "    unknown_value=-2,\n",
        "    encoded_missing_value=-1,\n",
        ")\n",
        "\n",
        "X_cat = category_encoder.fit_transform(df_train[cat_cols])\n",
        "for c, cat_col in enumerate(cat_cols):\n",
        "    df_train[cat_col] = X_cat[:, c]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wZabXb0FKNiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gkf = GroupKFold(n_splits=5) # , shuffle=True, random_state=42\n",
        "\n",
        "df_train[\"fold\"] = -1\n",
        "for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n",
        "    df_train.loc[val_idx, \"fold\"] = idx"
      ],
      "metadata": {
        "id": "cSYfFCj9KoDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "    v_pred = np.array([1.0 - x for x in submission.values])\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "    return partial_auc\n",
        "\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    \"random_state\": 42,\n",
        "    \"n_estimators\": 500,\n",
        "    'learning_rate': 0.01,\n",
        "    'bagging_freq': 1,\n",
        "    'pos_bagging_fraction': 0.75,\n",
        "    'neg_bagging_fraction': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'lambda_l1': 0.8,\n",
        "    'lambda_l2': 0.8,\n",
        "    \"verbosity\": -1,\n",
        "    # \"extra_trees\": True\n",
        "}\n",
        "\n",
        "scores = []\n",
        "models = []\n",
        "for fold in range(2):\n",
        "    _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
        "    _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
        "    model = lgb.LGBMRegressor(\n",
        "        **lgb_params\n",
        "    )\n",
        "    model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
        "    preds = model.predict(_df_valid[train_cols])\n",
        "    score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
        "    print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
        "    scores.append(score)\n",
        "    models.append(model)\n",
        "fold: 0 - Partial AUC Score: 0.15681\n",
        "fold: 1 - Partial AUC Score: 0.15737"
      ],
      "metadata": {
        "id": "qAqSj_-QKo18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(scores)\n",
        "0.157091496199396"
      ],
      "metadata": {
        "id": "0D9enxNBK-Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = np.mean([model.feature_importances_ for model in models], 0)\n",
        "df_imp = pd.DataFrame({\"feature\": model.feature_name_, \"importance\": importances}).sort_values(\"importance\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nG617CViK-FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does the new feature(s) perform?\n",
        "# I would go with the > 20 in the index.\n",
        "df_imp[df_imp[\"feature\"].isin(new_num_cols + new_cat_cols)].sort_values(\"importance\", ascending=False)"
      ],
      "metadata": {
        "id": "Rw1JRWm1K-B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# feature\timportance\n",
        "# 30\tmean_hue_difference\t1169.0\n",
        "# 29\thue_contrast\t918.0\n",
        "# 28\tnormalized_lesion_size\t785.5\n",
        "# 27\tlog_lesion_area\t779.5\n",
        "# 26\tcolor_uniformity\t776.5\n",
        "# 25\tsize_age_interaction\t776.0\n",
        "# 24\t3d_position_distance\t750.0\n",
        "# 23\tlesion_size_ratio\t749.5\n",
        "# 22\tcolor_contrast_index\t739.5\n",
        "# 21\t3d_lesion_orientation\t644.5\n",
        "# 20\tlesion_severity_index\t624.5\n",
        "# 19\tlesion_visibility_score\t613.5\n",
        "# 18\tlesion_color_difference\t604.0\n",
        "# 17\toverall_color_difference\t545.0\n",
        "# 16\tperimeter_to_area_ratio\t481.0\n",
        "# 15\tcolor_consistency\t470.0\n",
        "# 14\tsymmetry_perimeter_interaction\t379.0\n",
        "# 13\tcomprehensive_lesion_index\t372.5\n",
        "# 12\tluminance_contrast\t369.0\n",
        "# 11\thue_color_std_interaction\t339.5\n",
        "# 10\tsymmetry_border_consistency\t334.5\n",
        "# 8\tlesion_shape_index\t283.0\n",
        "# 7\tborder_complexity\t247.5\n",
        "# 6\tcolor_shape_composite_index\t240.5\n",
        "# 5\tcombined_anatomical_site\t235.5\n",
        "# 4\tshape_complexity_index\t156.0\n",
        "# 3\tstd_dev_contrast\t118.0\n"
      ],
      "metadata": {
        "id": "Dd_rNyOoK93m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_cat = category_encoder.fit_transform(df_test[cat_cols])\n",
        "for c, cat_col in enumerate(cat_cols):\n",
        "    df_test[cat_col] = X_cat[:, c]"
      ],
      "metadata": {
        "id": "c-1RGJpdLYbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.mean([model.predict(df_test[train_cols]) for model in models], 0)"
      ],
      "metadata": {
        "id": "fARvmIcZLbX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\n",
        "df_sub[\"target\"] = preds\n",
        "df_sub"
      ],
      "metadata": {
        "id": "_L3DPDo2LewN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "Lu-TO35ZLhb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
